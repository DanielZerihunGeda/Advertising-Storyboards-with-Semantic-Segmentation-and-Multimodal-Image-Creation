{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01malgorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize_blend\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[0;32m~/Advertising-Storyboards-with-Semantic-Segmentation-and-Multimodal-Image-Creation/Image_composing algorithm/algorithm.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Packages\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from typing import List, Literal, Tuple\n",
    "import itertools\n",
    "import random\n",
    "from algorithm import optimize_blend\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "import torch.nn.functional as F\n",
    "VERTICAL_POSITIONING = {'Logo': [1], 'CTA Button': [1, 2, 3], 'Icon': [1, 2, 3], 'Product Image': [2],\n",
    "                        'Text Elements': [1, 3], 'Infographic': [2], 'Banner': [1], 'Illustration': [2], 'Photograph': [2],\n",
    "                        'Mascot': [2], 'Testimonial Quotes': [2], 'Social Proof': [2, 1, 3], 'Seal or Badge': [3, 1, 2],\n",
    "                        'Graphs and Charts': [2], 'Decorative Elements': [3], 'Interactive Elements': [2], 'Animation': [2],\n",
    "                        'Coupon or Offer Code': [3], 'Legal Disclaimers or Terms': [3], 'Contact Information': [3, 1, 2],\n",
    "                        'Map or Location Image': [3], 'QR Code': [3, 1, 2]}\n",
    "\n",
    "HORIZONTAL_POSITIONING = {'Logo': [1], 'CTA Button': [2, 1, 3], 'Icon': [1], 'Product Image': [1],\n",
    "                          'Text Elements': [1], 'Infographic': [1], 'Banner': [2], 'Illustration': [2], 'Photograph': [2],\n",
    "                          'Mascot': [1], 'Testimonial Quotes': [2], 'Social Proof': [3, 1, 2], 'Seal or Badge': [3, 1, 2],\n",
    "                          'Graphs and Charts': [1], 'Decorative Elements': [3], 'Interactive Elements': [2], 'Animation': [2],\n",
    "                          'Coupon or Offer Code': [3], 'Legal Disclaimers or Terms': [3], 'Contact Information': [3, 1, 2],\n",
    "                          'Map or Location Image': [3], 'QR Code': [3, 1, 2]}\n",
    "\n",
    "\n",
    "class ImageComposer:\n",
    "    categories = Literal[\"Background\", \"Logo\", \"CTA Button\", \"Icon\", \"Product Image\", \"Text Elements\", \"Infographic\", \"Banner\", \"Illustration\", \"Photograph\", \"Mascot\", \"Testimonial Quotes\", \"Social Proof\", \"Seal or Badge\", \"Graphs and Charts\", \"Decorative Elements\", \"Interactive Elements\", \"Animation\", \"Coupon or Offer Code\", \"Legal Disclaimers or Terms\", \"Contact Information\", \"Map or Location Image\", \"QR Code\"]\n",
    "    PositionSegment = Tuple[float, float]\n",
    "    AlignmentPosition = Tuple[int, int]\n",
    "    AlignmentPositions = List[AlignmentPosition]\n",
    "    frame_images = List[Tuple[categories, str, str]]\n",
    "\n",
    "    def __init__(self, width:int, height: int, frames: List[frame_images]) -> None:\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.frames = frames\n",
    "        self.segments = ImageComposer.get_image_position_segments(width, height)\n",
    "        self.generated_frames = []\n",
    "\n",
    "    def generate_frames(self):\n",
    "        self.compose_frames()\n",
    "        return self.generated_frames\n",
    "\n",
    "    def compose_frames(self) -> None:\n",
    "        self.generated_frames = []\n",
    "\n",
    "        for frame in self.frames:\n",
    "            # Extract background, mask, and target images from the frame\n",
    "            background_path = None\n",
    "            mask_path = None\n",
    "            target_path = None\n",
    "            for category, url_path, local_path in frame:\n",
    "                if category == 'Background':\n",
    "                    background_path = local_path\n",
    "                elif category == 'Mask':  # Assuming there's a category named 'Mask'\n",
    "                    mask_path = local_path\n",
    "                else:\n",
    "                    target_path = local_path\n",
    "            \n",
    "            if background_path is None or target_path is None:\n",
    "                continue  # Skip frame if background or target image is missing\n",
    "\n",
    "            # Call optimize_blend function with the extracted paths\n",
    "            blended_image = optimize_blend(background_path, mask_path, target_path)\n",
    "\n",
    "            # Add the blended image to generated_frames\n",
    "            self.generated_frames.append(blended_image)\n",
    "    @staticmethod\n",
    "    def compute_positions(elements: List[categories]) -> List[AlignmentPositions]:\n",
    "        possible_positions = []\n",
    "\n",
    "        # Iterate through each element to calculate its position combinations\n",
    "        for element in elements:\n",
    "            vertical_options = VERTICAL_POSITIONING[element]\n",
    "            horizontal_options = HORIZONTAL_POSITIONING[element]\n",
    "            combinations = list(itertools.product(vertical_options, horizontal_options))\n",
    "            possible_positions.append(combinations)\n",
    "\n",
    "        return possible_positions\n",
    "\n",
    "    @staticmethod\n",
    "    def select_diverse_positions(possible_positions: List[AlignmentPositions]) -> AlignmentPositions:\n",
    "        position_frequency = defaultdict(int)\n",
    "\n",
    "        def update_position_frequency(selected_position):\n",
    "            position_frequency[selected_position] += 1\n",
    "\n",
    "        selected_positions = []\n",
    "\n",
    "        for positions in possible_positions:\n",
    "            sorted_combinations = sorted(positions, key=lambda x: position_frequency[x])\n",
    "\n",
    "            lowest_frequency = position_frequency[sorted_combinations[0]]\n",
    "            lowest_freq_combinations = [pos for pos in sorted_combinations if position_frequency[pos] == lowest_frequency]\n",
    "\n",
    "            selected_position = random.choice(lowest_freq_combinations)\n",
    "            selected_positions.append(selected_position)\n",
    "\n",
    "            update_position_frequency(selected_position)\n",
    "\n",
    "        return selected_positions\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_image_position_segments(width: float, height: float, vm: float = 0.6, vo: float = 0.2, hm: float = 0.6, ho: float = 0.2) -> Tuple[List[PositionSegment], List[PositionSegment]]:\n",
    "        \"\"\"Divide Image based on percentage for vertical and horizontal segments.\"\"\"\n",
    "\n",
    "        if vm + vo * 2 > 1 or hm + ho * 2 > 1:\n",
    "            raise ValueError(\"Sum of percentages exceeds 100% for either vertical or horizontal segments.\")\n",
    "\n",
    "        vertical_mid = height * vm\n",
    "        vertical_outer = height * vo\n",
    "        horizontal_mid = width * hm\n",
    "        horizontal_outer = width * ho\n",
    "\n",
    "        vertical_segments = [\n",
    "            (0, vertical_outer),\n",
    "            (vertical_outer, vertical_outer + vertical_mid),\n",
    "            (vertical_outer + vertical_mid, height)\n",
    "        ]\n",
    "\n",
    "        horizontal_segments = [\n",
    "            (0, horizontal_outer),\n",
    "            (horizontal_outer, horizontal_outer + horizontal_mid),\n",
    "            (horizontal_outer + horizontal_mid, width)\n",
    "        ]\n",
    "\n",
    "        segements = []\n",
    "        for vs in vertical_segments:\n",
    "            vs_items = []\n",
    "            for hs in horizontal_segments:\n",
    "                vs_items.append((vs, hs))\n",
    "            segements.append(vs_items)\n",
    "\n",
    "\n",
    "        return segements\n",
    "\n",
    "    def calculate_adjusted_element_positions(self, elements_positions, padding=10):\n",
    "        element_details = []\n",
    "        segment_elements = {}\n",
    "\n",
    "        # Organize elements by their segments\n",
    "        for i, (v_pos, h_pos) in enumerate(elements_positions):\n",
    "            segment_key = (v_pos, h_pos)\n",
    "            if segment_key not in segment_elements:\n",
    "                segment_elements[segment_key] = []\n",
    "            segment_elements[segment_key].append(i)\n",
    "\n",
    "        for segment_key, elements in segment_elements.items():\n",
    "            v_pos, h_pos = segment_key\n",
    "            segment = self.segments[v_pos-1][h_pos-1]\n",
    "            vertical_segment, horizontal_segment = segment\n",
    "            num_elements = len(elements)\n",
    "\n",
    "            x_start, x_end = horizontal_segment\n",
    "            y_start, y_end = vertical_segment\n",
    "            segment_width = (x_end - x_start) - 2 * padding\n",
    "            segment_height = (y_end - y_start) - 2 * padding\n",
    "\n",
    "            # Determine alignment and divide space\n",
    "            is_vertical = segment_height > segment_width\n",
    "            if is_vertical:\n",
    "                space_per_element = segment_height / num_elements\n",
    "            else:\n",
    "                space_per_element = segment_width / num_elements\n",
    "\n",
    "            for index, _ in enumerate(elements):\n",
    "                if is_vertical:\n",
    "                    element_x_start = x_start + padding\n",
    "                    element_y_start = y_start + padding + index * space_per_element\n",
    "                    element_width = segment_width\n",
    "                    element_height = space_per_element\n",
    "                else:\n",
    "                    element_x_start = x_start + padding + index * space_per_element\n",
    "                    element_y_start = y_start + padding\n",
    "                    element_width = space_per_element\n",
    "                    element_height = segment_height\n",
    "\n",
    "                element_details.append({\n",
    "                    \"start_point\": (element_x_start, element_y_start),\n",
    "                    \"dimensions\": (element_width, element_height)\n",
    "                })\n",
    "\n",
    "        return element_details\n",
    "\n",
    "    @staticmethod\n",
    "    @staticmethod\n",
    "    def resize_image(image, target_width, target_height):\n",
    "        \"\"\"\n",
    "        Resize an image to fit within target dimensions while maintaining aspect ratio.\n",
    "        \"\"\"\n",
    "        original_width, original_height = image.size\n",
    "        ratio = min(target_width / original_width, target_height / original_height)\n",
    "        new_width = int(original_width * ratio)\n",
    "        new_height = int(original_height * ratio)\n",
    "        resized_image = image.resize((new_width, new_height), Image.LANCZOS)  # or Image.BICUBIC\n",
    "        return resized_image\n",
    "\n",
    "\n",
    "    def create_combined_image(self, background_path: str, elements: List[Tuple[str, int|float, int|float]]):\n",
    "        \"\"\"\n",
    "        Create a combined image based on background and elements' positioning and sizing.\n",
    "\n",
    "        :param background_path: Path to the background image.\n",
    "        :param elements: A list of tuples containing 'image_path', 'start_point', and 'dimensions'.\n",
    "        \"\"\"\n",
    "        # Load the background image\n",
    "        background = Image.open(background_path).convert(\"RGBA\")\n",
    "\n",
    "        # Blend each element onto the background\n",
    "        for element in elements:\n",
    "            # Load element image\n",
    "            image_path = element[0]\n",
    "            element_image = Image.open(image_path).convert(\"RGBA\")\n",
    "\n",
    "            # Resize image according to dimensions without losing aspect ratio\n",
    "            target_width, target_height = element[2]\n",
    "            resized_element_image = ImageComposer.resize_image(element_image, target_width, target_height)\n",
    "\n",
    "            # Calculate position to place the image within its segment\n",
    "            start_x, start_y = element[1]\n",
    "            offset_x = start_x + (target_width - resized_element_image.size[0]) / 2\n",
    "            offset_y = start_y + (target_height - resized_element_image.size[1]) / 2\n",
    "\n",
    "            # Blend the element onto the background using the blending algorithm\n",
    "            background = algorithm.optimize_blend(background, resized_element_image, (int(offset_x), int(offset_y)))\n",
    "\n",
    "        return background\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ic = ImageComposer(320, 500, [[('Logo', 'url_path', 'local_path'),\n",
    "                                   ('CTA Button', 'url_path', 'local_path'),\n",
    "                                   ('Icon', 'url_path', 'local_path'),\n",
    "                                   ('Product Image', 'url_path', 'local_path'),\n",
    "                                   ('Text Elements', 'url_path', 'local_path')]])\n",
    "    possibilties = ImageComposer.compute_positions([\"Logo\", \"CTA Button\", \"Icon\", \"Product Image\", \"Text Elements\"])\n",
    "    pprint(possibilties)\n",
    "    print(\"======================================================\")\n",
    "    diverse = ImageComposer.select_diverse_positions(possibilties)\n",
    "    pprint(diverse)\n",
    "\n",
    "    print(ic.calculate_adjusted_element_positions(diverse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
